# infra/k8s/litellm.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-gateway
  namespace: ai-platform
  labels:
    app: llm-gateway
    layer: L2-platform
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llm-gateway
  template:
    metadata:
      labels:
        app: llm-gateway
    spec:
      containers:
        - name: litellm
          image: ghcr.io/berriai/litellm:main-latest
          imagePullPolicy: IfNotPresent
          args:
            - "--config"
            - "/app/config.yaml"
            - "--port"
            - "4000"
          ports:
            - containerPort: 4000
          env:
            - name: GEMINI_API_KEY
              valueFrom:
                secretKeyRef:
                  name: llm-secret
                  key: GEMINI_API_KEY
          volumeMounts:
            - name: config-volume
              mountPath: /app/config.yaml
              subPath: config.yaml
              readOnly: true
      volumes:
        - name: config-volume
          configMap:
            name: litellm-config
---
apiVersion: v1
kind: Service
metadata:
  name: llm-service
  namespace: ai-platform
spec:
  selector:
    app: llm-gateway
  ports:
    - protocol: TCP
      port: 4000
      targetPort: 4000
  type: ClusterIP